{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.transforms\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "import torch\n",
    "import numpy as np\n",
    "from keypoint_detection.utils.heatmap import generate_channel_heatmap, get_keypoints_from_heatmap\n",
    "from keypoint_detection.utils.visualization import overlay_image_with_heatmap\n",
    "from keypoint_detection.models.detector import KeypointDetector\n",
    "from keypoint_detection.data.unlabeled_dataset import UnlabeledKeypointsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Get Model checkpoint from wandb\n",
    "\n",
    "\n",
    "checkpoint_reference = 'airo-box-manipulation/clothes/model-1kkjks2v:v1'\n",
    "\n",
    "# download checkpoint locally (if not already cached)\n",
    "run = wandb.init(project=\"clothes\", entity=\"airo-box-manipulation\")\n",
    "artifact = run.use_artifact(checkpoint_reference, type=\"model\")\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "# \n",
    "#checkpoint = torch.load(Path(artifact_dir) / \"model.ckpt\")\n",
    "#print(checkpoint[\"hyper_parameters\"])\n",
    "# load checkpoint\n",
    "# ,map_location={\"cuda:0\":\"cpu\"}\n",
    "model = KeypointDetector.load_from_checkpoint(Path(artifact_dir) / \"model.ckpt\",backbone_type='ConvNeXtUnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "home = os.path.expanduser(\"~\")\n",
    "dataset_dir = os.path.join(home, \"cloth-keypoint-generation\", \"datasets\", \"towel_dataset_2\")\n",
    "JSON_PATH = os.path.join(dataset_dir, \"annotations.json\")\n",
    "IMAGE_DIR = os.path.join(dataset_dir, \"images\")\n",
    "\n",
    "\n",
    "print(JSON_PATH)\n",
    "dataset = UnlabeledKeypointsDataset(IMAGE_DIR)\n",
    "print(len(dataset))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size= 4, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    \"\"\"\n",
    "    plot Tensor as image\n",
    "    images are kept in the [0,1] range, although in theory [-1,1] should be used to whiten..\n",
    "    \"\"\"\n",
    "    np_img = img.numpy()\n",
    "    # bring (C,W,H) to (W,H,C) dims\n",
    "    img = np.transpose(np_img, (1,2,0))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = next(iter(dataloader))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transform  = torchvision.transforms.Resize((256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def crop(img_batch, start_v, height, start_u, width):\n",
    "#     return img_batch[:,:,start_v: start_v +height, start_u: start_u + width]\n",
    "\n",
    "img = next(iter(dataloader))\n",
    "# cropped  =crop(img, 250, 350, 300, 450)\n",
    "imshow(img[0])\n",
    "# imshow(cropped[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_results(show_extracted_keypoints = True, mode =\"eval\"):\n",
    "    \"\"\"\n",
    "    show network outputs on the dataset.\n",
    "    \"\"\"\n",
    "    plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "    pil_to_torch = torchvision.transforms.ToTensor()\n",
    "    if mode == \"eval\":\n",
    "        model.eval()\n",
    "    else:\n",
    "        model.train()\n",
    "    for batch in iter(dataloader):\n",
    "        with torch.no_grad():\n",
    "            # batch = crop(batch, 250, 350, 300, 500)\n",
    "            batch = transform(batch)\n",
    "            channel = 0\n",
    "            output = model(batch)[:,channel]\n",
    "            if not show_extracted_keypoints:\n",
    "                overlayed_heatmap = torch.stack(\n",
    "                    [\n",
    "                        pil_to_torch(overlay_image_with_heatmap(batch[i], torch.unsqueeze(output[i].cpu(), 0),0.6))\n",
    "                        for i in range(batch.shape[0])\n",
    "                    ]\n",
    "                )\n",
    "            else:\n",
    "                n_keypoints = 4\n",
    "                overlayed_heatmap = torch.stack(\n",
    "                [\n",
    "                    pil_to_torch(\n",
    "                        overlay_image_with_heatmap(\n",
    "                            batch[i],\n",
    "                            torch.unsqueeze(\n",
    "                                generate_channel_heatmap(\n",
    "                                    batch.shape[-2:],\n",
    "\n",
    "                                    get_keypoints_from_heatmap(output[i].cpu(), 30,n_keypoints),\n",
    "                                    sigma=4,\n",
    "                                    device = 'cpu'\n",
    "                                ),\n",
    "                                0,\n",
    "                            ),\n",
    "                            0.6\n",
    "                        )\n",
    "                    )\n",
    "                    for i in range(batch.shape[0])\n",
    "                ]\n",
    "        )\n",
    "        grid = torchvision.utils.make_grid(overlayed_heatmap, nrow=8)\n",
    "        imshow(grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show_results(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('keypoint-detection')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2ebc60e4e73209e16096be3b13acee9d1da114b499be2a6db93f392e5e51725a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
